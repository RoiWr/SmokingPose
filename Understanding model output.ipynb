{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = 'smokin2mp4.pkl'\n",
    "with open(DATA_FILE_PATH, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data format: list of dicts for the analyzed frames of the following fields:\n",
    "{'frame_id', 'body_parts', 'all_peaks', 'subset', 'candiate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_BODY_PARTS = ['nose', 'neck',\n",
    "                   'right_shoulder', ' right_elbow', 'right_wrist',\n",
    "                   'left_shoulder', 'left_elbow', 'left_wrist',\n",
    "                   'right_hip', 'right_knee', 'right_ankle',\n",
    "                   'left_hip', 'left_knee', 'left_ankle',\n",
    "                   'right_eye', 'left_eye', 'right_ear', 'left_ear', 'background'\n",
    "                   ]\n",
    "len(COCO_BODY_PARTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## body parts\n",
    "one example of coordiinates for every COCO body part. USELESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'nose': (230, 87), 'neck': (145, 100), 'right_shoulder': (228, 97), ' right_elbow': (127, 114), 'right_wrist': (130, 129), 'left_shoulder': (157, 100), 'left_elbow': (159, 121), 'left_wrist': (145, 133), 'right_hip': (229, 134), 'right_knee': (226, 156), 'right_ankle': (223, 174), 'left_hip': (154, 134), 'left_knee': (153, 160), 'left_ankle': (151, 184), 'right_eye': (229, 84), 'left_eye': (233, 84), 'right_ear': (138, 88), 'left_ear': (241, 85)},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_parts = np.array(data[25]['body_parts'])\n",
    "body_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_peaks\n",
    "a list of lists each corresponding to a COCO body part made of tuples of the following format of locs:\n",
    "(x, y, confidence, peak_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([(234, 87, 0.9083782434463501, 0), (181, 96, 0.5591726899147034, 1)]),\n",
       "       list([(169, 99, 0.765608012676239, 2), (241, 100, 0.9036915898323059, 3), (196, 118, 0.8418397307395935, 4)]),\n",
       "       list([(230, 97, 0.864372193813324, 5), (163, 100, 0.8208009600639343, 6), (210, 124, 0.8031818270683289, 7)]),\n",
       "       list([(227, 114, 0.7221102118492126, 8), (158, 120, 0.8832500576972961, 9), (215, 151, 0.8135343790054321, 10)]),\n",
       "       list([(178, 115, 0.6068695187568665, 11), (226, 129, 0.6727707982063293, 12), (232, 157, 0.5008898377418518, 13)]),\n",
       "       list([(177, 99, 0.5348705053329468, 14), (251, 103, 0.8400102257728577, 15), (182, 113, 0.7927486896514893, 16)]),\n",
       "       list([(252, 124, 0.8243544101715088, 17)]),\n",
       "       list([(244, 142, 0.7252730131149292, 18)]),\n",
       "       list([(167, 134, 0.8585205674171448, 19), (230, 134, 0.7712255120277405, 20), (204, 167, 0.680644690990448, 21)]),\n",
       "       list([(226, 155, 0.8229906558990479, 22), (167, 157, 0.8823679089546204, 23), (201, 197, 0.7733970284461975, 24)]),\n",
       "       list([(224, 175, 0.8872216939926147, 25), (165, 180, 0.9053114056587219, 26), (197, 223, 0.406983345746994, 27)]),\n",
       "       list([(177, 133, 0.7303912043571472, 28), (242, 137, 0.7648066282272339, 29), (189, 163, 0.6958182454109192, 30)]),\n",
       "       list([(175, 155, 0.7930884957313538, 31), (238, 161, 0.7691529393196106, 32), (187, 193, 0.7661322355270386, 33)]),\n",
       "       list([(173, 173, 0.8188678026199341, 34), (236, 184, 0.8541661500930786, 35), (184, 216, 0.4622024595737457, 36)]),\n",
       "       list([(233, 83, 0.8554295301437378, 37), (179, 93, 0.5754064917564392, 38)]),\n",
       "       list([(237, 84, 0.9530988931655884, 39), (184, 94, 0.269801527261734, 40)]),\n",
       "       list([(174, 90, 0.5507457852363586, 41), (207, 97, 0.7828583121299744, 42)]),\n",
       "       list([(244, 85, 0.8881293535232544, 43), (191, 96, 0.3839954733848572, 44)])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_peaks = np.array(data[0]['all_peaks'])\n",
    "all_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset\n",
    "an array in which each row corresponds to a different \"object\" with the row items indicating the peak_id's in all_peaks. the column index corresponds to the COCO body part index\n",
    "\n",
    "    # last number in each row is the total parts number of that person\n",
    "    # the second last number in each row is the score of the overall configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.        ,  5.        ,  8.        , 12.        ,\n",
       "        15.        , 17.        , 18.        , 20.        , 22.        ,\n",
       "        25.        , 29.        , 32.        , 35.        , 37.        ,\n",
       "        39.        , -1.        , 43.        , 28.89961997, 17.        ],\n",
       "       [-1.        ,  4.        ,  7.        , 10.        , 13.        ,\n",
       "        16.        , -1.        , -1.        , 21.        , 24.        ,\n",
       "        27.        , 30.        , 33.        , 36.        , -1.        ,\n",
       "        -1.        , 42.        , 44.        , 18.56997137, 13.        ],\n",
       "       [ 1.        ,  2.        ,  6.        ,  9.        , 11.        ,\n",
       "        14.        , -1.        , -1.        , 19.        , 23.        ,\n",
       "        26.        , 28.        , 31.        , 34.        , 38.        ,\n",
       "        40.        , 41.        , -1.        , 21.81312792, 15.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = np.array(data[0]['subset'])\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate\n",
    "array in which each row is one of the peaks, same as each tuple in all_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[234.        ,  87.        ,   0.90837824,   0.        ],\n",
       "       [181.        ,  96.        ,   0.55917269,   1.        ],\n",
       "       [169.        ,  99.        ,   0.76560801,   2.        ],\n",
       "       [241.        , 100.        ,   0.90369159,   3.        ],\n",
       "       [196.        , 118.        ,   0.84183973,   4.        ],\n",
       "       [230.        ,  97.        ,   0.86437219,   5.        ],\n",
       "       [163.        , 100.        ,   0.82080096,   6.        ],\n",
       "       [210.        , 124.        ,   0.80318183,   7.        ],\n",
       "       [227.        , 114.        ,   0.72211021,   8.        ],\n",
       "       [158.        , 120.        ,   0.88325006,   9.        ],\n",
       "       [215.        , 151.        ,   0.81353438,  10.        ],\n",
       "       [178.        , 115.        ,   0.60686952,  11.        ],\n",
       "       [226.        , 129.        ,   0.6727708 ,  12.        ],\n",
       "       [232.        , 157.        ,   0.50088984,  13.        ],\n",
       "       [177.        ,  99.        ,   0.53487051,  14.        ],\n",
       "       [251.        , 103.        ,   0.84001023,  15.        ],\n",
       "       [182.        , 113.        ,   0.79274869,  16.        ],\n",
       "       [252.        , 124.        ,   0.82435441,  17.        ],\n",
       "       [244.        , 142.        ,   0.72527301,  18.        ],\n",
       "       [167.        , 134.        ,   0.85852057,  19.        ],\n",
       "       [230.        , 134.        ,   0.77122551,  20.        ],\n",
       "       [204.        , 167.        ,   0.68064469,  21.        ],\n",
       "       [226.        , 155.        ,   0.82299066,  22.        ],\n",
       "       [167.        , 157.        ,   0.88236791,  23.        ],\n",
       "       [201.        , 197.        ,   0.77339703,  24.        ],\n",
       "       [224.        , 175.        ,   0.88722169,  25.        ],\n",
       "       [165.        , 180.        ,   0.90531141,  26.        ],\n",
       "       [197.        , 223.        ,   0.40698335,  27.        ],\n",
       "       [177.        , 133.        ,   0.7303912 ,  28.        ],\n",
       "       [242.        , 137.        ,   0.76480663,  29.        ],\n",
       "       [189.        , 163.        ,   0.69581825,  30.        ],\n",
       "       [175.        , 155.        ,   0.7930885 ,  31.        ],\n",
       "       [238.        , 161.        ,   0.76915294,  32.        ],\n",
       "       [187.        , 193.        ,   0.76613224,  33.        ],\n",
       "       [173.        , 173.        ,   0.8188678 ,  34.        ],\n",
       "       [236.        , 184.        ,   0.85416615,  35.        ],\n",
       "       [184.        , 216.        ,   0.46220246,  36.        ],\n",
       "       [233.        ,  83.        ,   0.85542953,  37.        ],\n",
       "       [179.        ,  93.        ,   0.57540649,  38.        ],\n",
       "       [237.        ,  84.        ,   0.95309889,  39.        ],\n",
       "       [184.        ,  94.        ,   0.26980153,  40.        ],\n",
       "       [174.        ,  90.        ,   0.55074579,  41.        ],\n",
       "       [207.        ,  97.        ,   0.78285831,  42.        ],\n",
       "       [244.        ,  85.        ,   0.88812935,  43.        ],\n",
       "       [191.        ,  96.        ,   0.38399547,  44.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate = np.array(data[0]['candidate'])\n",
    "candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data structure per person in video\n",
    "Try to create a 3D array of coordinates and time for each person\n",
    "\n",
    "1) parse pkl for coordinates for each body part per frame\n",
    "\n",
    "2) match same person between frames - based on the minimum change in head location between consecutive frames\n",
    "\n",
    "3) filter in time out bad pose estimates, based on:\n",
    "    a. smoothing filter\n",
    "    b. pose estimate confidence\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many persons there are in the video?\n",
    "Go over all frames and understand what is the average number of people.\n",
    "\n",
    "Choose representative middle frame from which to identify persons accross frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_persons_video(data, person_thresh=0): # TODO: need to figure out person configuration score threshold\n",
    "    no_persons = np.zeros(len(data))\n",
    "    for i, frame_data in enumerate(data):\n",
    "        subset = np.array(frame_data['subset'])\n",
    "        for person in subset:\n",
    "            if person[18] > person_thresh:\n",
    "                no_persons[i] += 1\n",
    "    return no_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 3., 3., 3., 3., 3., 3., 4.,\n",
       "       3., 3., 3., 3., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "how_many_persons_video(data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frame level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_peaks = np.array(data[0]['all_peaks'])\n",
    "subset = np.array(data[0]['subset'])\n",
    "candidate = np.array(data[0]['candidate'])\n",
    "person_thresh = 0 \n",
    "joint_thresh = 0\n",
    "\n",
    "def get_person_pose_frame(person, candidate, person_thresh=0, joint_thresh=0):\n",
    "    ''' extracts body positions for given person (item in the \"subset\" list)'''\n",
    "    confidence = person[18]     # check confidence level\n",
    "    if confidence < person_thresh:\n",
    "        return False\n",
    "    joints = person[0:18]\n",
    "    joints_locs = np.zeros((18, 2))\n",
    "    for i, joint in enumerate(joints):\n",
    "        j = int(joint)\n",
    "        if joint == -1:\n",
    "            joints_locs[i, :] = [-1, -1]\n",
    "        elif candidate[j, 2] < joint_thresh:\n",
    "            joints_locs[i, :] = [-1, -1]\n",
    "        else:\n",
    "            joints_locs[i, :] = candidate[j, 0:2]\n",
    "            \n",
    "    return joints_locs\n",
    "\n",
    "# check\n",
    "for person in subset:\n",
    "    joints_locs = get_person_pose_frame(person, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[181.,  96.],\n",
       "       [169.,  99.],\n",
       "       [163., 100.],\n",
       "       [158., 120.],\n",
       "       [178., 115.],\n",
       "       [177.,  99.],\n",
       "       [ inf,  inf],\n",
       "       [ inf,  inf],\n",
       "       [167., 134.],\n",
       "       [167., 157.],\n",
       "       [165., 180.],\n",
       "       [177., 133.],\n",
       "       [175., 155.],\n",
       "       [173., 173.],\n",
       "       [179.,  93.],\n",
       "       [184.,  94.],\n",
       "       [174.,  90.],\n",
       "       [ inf,  inf]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joints_locs[joints_locs <= 0] = np.inf\n",
    "joints_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching between persons in different frames\n",
    "So run previous function on all frames, see when getting head locations, and them match them based on minimal head loc change distanvce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form sklearn.metrics import pairwise_distances\n",
    "# get max characters in video\n",
    "n_joints = 18\n",
    "head_loc_idx = 1\n",
    "max_no_people = max(how_many_persons_video(data))\n",
    "n_frames = len(data)\n",
    "joints_array = np.zeros((n_joints, 2, max_no_people, n_frames))\n",
    "\n",
    "for i, frame_data in enumerate(data):\n",
    "    subset = np.array(frame_data['subset'])\n",
    "\n",
    "    if i == 0:\n",
    "        for p, person in enumerate(subset):\n",
    "            joints_locs = get_person_pose_frame(person, candidate)\n",
    "            joints_array[:, :, p, i] = joints_locs\n",
    "            \n",
    "    else:\n",
    "        for p, person in enumerate(subset):\n",
    "            joints_locs = get_person_pose_frame(person, candidate)\n",
    "            head_loc = joints_loc[head_loc_idx, :]\n",
    "            dist_mat = pairwise_distances(head_loc, joints_array[head_loc_idx, :, :, i-1], \n",
    "                                          metric='euclidean', n_jobs=-1)\n",
    "            min_idx = np.argmin(dist_mat)\n",
    "            joints_array[:, :, p, i] = joints_locs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create bounding box for head location per person to be used in SORT tracking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_pose_frame(person, candidate, person_thresh=0, joint_thresh=0):\n",
    "    ''' extracts body positions for given person (item in the \"subset\" list) '''\n",
    "    no_joints = person[19]\n",
    "    config_score = person[18]     # check configuration score\n",
    "    if config_score < person_thresh:\n",
    "        return False\n",
    "    joints = person[0:18]\n",
    "    joints_locs = np.zeros((18, 2))\n",
    "    for i, joint in enumerate(joints):\n",
    "        j = int(joint)\n",
    "        if joint == -1 or j >= len(candidate):\n",
    "            joints_locs[i, :] = [-1, -1]\n",
    "        elif candidate[j, 2] < joint_thresh:\n",
    "            joints_locs[i, :] = [-1, -1]\n",
    "        else:\n",
    "            joints_locs[i, :] = candidate[j, 0:2]\n",
    "            \n",
    "    return joints_locs, config_score, no_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_from_pose(joints_locs):\n",
    "    joints_locs_min = joints_locs.copy()\n",
    "    joints_locs_min[joints_locs <= 0] = np.inf\n",
    "    \n",
    "    minx = min(joints_locs_min[:, 0])\n",
    "    miny = min(joints_locs_min[:, 1])\n",
    "    maxx = max(joints_locs[:, 0])\n",
    "    maxy = max(joints_locs[:, 1])\n",
    "    return [minx, miny, maxx, maxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_joints(data):\n",
    "    '''Function outputs an array of detected persons in each frame , \n",
    "    their joint body parts x, y locations and bounding box [x1,y1,x2,y2]'''\n",
    "    joints_array = []\n",
    "    for i, frame_data in enumerate(data):\n",
    "        # print(f'Processing frame {i}')\n",
    "        subset = np.array(frame_data['subset'])\n",
    "        for person in subset:\n",
    "            joints_locs, confidence, no_joints = get_person_pose_frame(person, candidate)\n",
    "            bboxes = get_bbox_from_pose(joints_locs)\n",
    "            joints_array.append([i] + list(bboxes) + list(joints_locs.flatten())+ [confidence, no_joints])\n",
    "    return np.array(joints_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "joints_array = get_all_joints(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(4, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(4, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(4, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(4, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "-----------------------------\n",
      "(131,)\n",
      "(143, 43)\n"
     ]
    }
   ],
   "source": [
    "from sort.sort import *\n",
    "\n",
    "#create instance of SORT\n",
    "mot_tracker = Sort() \n",
    "\n",
    "# get detections\n",
    "joints_array = get_all_joints(data)\n",
    "object_ids = []\n",
    "for i in range(len(data)):\n",
    "    detections = joints_array[joints_array[:, 0] == i, 1:5]\n",
    "    # update SORT\n",
    "    # trackers is a np array where each row contains a valid bounding box and track_id (last column)\n",
    "    print(detections.shape)\n",
    "    trackers = mot_tracker.update(detections)\n",
    "    print(trackers.shape)\n",
    "    print('-----------------------------')\n",
    "    object_ids += list(trackers[:, -1])\n",
    "    \n",
    "# concatenate object ids as new column to joints_array\n",
    "object_ids = np.array(object_ids) - min(object_ids) # reindex from 0\n",
    "print(object_ids.shape)\n",
    "print(joints_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42.0, 41.0, 40.0, 42.0, 41.0, 40.0, 42.0, 41.0, 40.0, 41.0, 40.0, 41.0, 40.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 44.0, 43.0, 41.0, 43.0, 41.0, 43.0, 41.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 41.0, 40.0, 41.0, 40.0, 41.0, 40.0, 41.0, 40.0, 43.0, 41.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0, 43.0, 40.0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-690c57244228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# concatenate object ids as new column to joints_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mobject_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# reindex from 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mjoints_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joints_array = np.column_stack((joints_array, object_ids))\n",
    "print(joints_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(object_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
